---
output: html_document
author: Hennie Engebretsen
chunk_output_type: console
---
Assignment 3: Drawing inference from statistical models, and statistical power


## Oppgave 1

```{r}
#| message: false
#| warning: false
#| code-fold: true

library(tidyverse)

set.seed(1)
population <- rnorm(1000000, mean = 1.5, sd = 3)


samp1 <- data.frame(y = sample(population, 8, replace = FALSE))

samp2 <- data.frame(y = sample(population, 40, replace = FALSE))


m1 <- lm(y ~ 1, data = samp1)
m2 <- lm(y ~ 1, data = samp2)

summary(m1)

mean(samp1$y)
coef(m1)
sd(samp1$y)
sd(samp1$y) /sqrt(8)

```


Ved bruk av regresjonsmodellene lm1 og lm2 skal begrepene estimat, SE (standard error) t-verdi og p-verdi forklares.

Et estimat representererer gjennomsnittet av det vi har målt i utvalget. Det vil i lm1 og lm2 estimat gjennomsnitt på den ene variablen (y) i de to ulike utvalgene. 

SE(standard error) er standardfeilen vil være et mål på hvordan et statisitsk estimat til et utvalg kan variere fra populasjonen. For modellen m1 er standard error 1.25 dette viser at det er noe usikkerhet knyttet til et estimat av gjennomsnittet.

T-verdi kan ses på som en statisitksk verdi hvor et forhold mellom estimatet og stndardfeilen. 

P-verdi sier noe om hvis vi skulle gjentatt forsøket igjen om sannsynligheten om vi da vile fått et resultat som er like ekstremt eller mer ekstremt enn det vi har observert. I denne modellen har vi fått en verdi som er høyere enn p <0.05 som vil si at vi ikke kan forkaste den null-hypotesen vi har.  

### Oppgave 2

De to ulike modellene får ulike resultater en av grunnene til dette er at det er ulikt utvalg i de to ulike modellene i lm1 er det n =8, mens i lm2 er det n =40. Utvalgsstørrelsen vil ha en innvirkning på resultatene, ved at man har et større utvalg vil den statistiske styrken være høyere og det vil dermed være lettere å kunne oppdage om det vil være en reell effekt en ser. Det samme vil gjelde for standardfeil ved et større utvalg vil standardfeil til gjennomsnittet reduseres, en vil da ha mindre konfidensintervall og estimatene vil kunne bli mer presist.

## Oppgave 3

De mørke skyggeområdene til modellen viser de mer "ekstreme" og at vi da kan forkaste null-hypotesen.

## Oppgave 4

```{r}
#| message: false
#| warning: false
#| code-fold: true

library(tidyverse)

# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results <- bind_rows(results_8, results_40)


```

```{r}
#| message: false
#| warning: false
#| code-fold: true
sd_est_8 <- sd (results_8$estimate)
mean_se_8 <- mean(results_8$se)

sd_est_40 <- sd (results_40$estimate)
mean_se_40 <- mean(results_40$se)

```

Vi får ganske like tall i modellene for sd og mean er at beregningene er et mål på variasjonen, vi ser at i disse to utvalgene at det er forholdsvis likt er fordi det er en beregning på variasjon. 

## Oppgave 5

```{r}
# Example code for copy and paste

# A two facets histogram can be created with ggplot2
results %>%
  ggplot(aes(pval)) + 
  geom_histogram() +
  facet_wrap(~ n)


# Count the proportion of tests below a certain p-value for each 
results %>%
  filter(pval < 0.05) %>%
  group_by(n) %>%
  summarise(sig_results = n()/1000)

# Using the pwr package
library(pwr)

pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = "one.sample")
```


```

## Oppgave 5

I de to histogrammene har vi ulike størrelse på utvalget n =8 og n =40. Ved å se på histogrammene ser vi at i utvalget med n = 8 er det et mer spredt fordeling av p-verdiene og at få p-verdier ligger i signifikansområdet. Et mindre utvalg gir lavere statistisk styrke og at det vil være mindre sannsynligheten for å kunne oppdage om et forsøk faktisk gir en effekt, samt at det er større spredning i utvalget som ikke gir en signifikant p-verdi. Ser vi på histogrammet med et utvalg n =40 ligger p-verdiene mer samlet og større del av utvalget ligger i det signifikante området, dette gjør at den statiske styrken er høyere. Ved en høy statistisk styrke og flere signifikante p-verdier gjør at det vil være en høyere sannsynlighet for å kunne oppdage de faktiske effektene.

## Oppgave 6

```{r}

#| message: false
#| warning: false
#| code-fold: true

library(tidyverse)
library(pwr)
library(ggplot2)
library(dplyr)

# Count the proportion of tests below a certain p-value for each 
results %>%
  filter(pval < 0.05) %>%
  group_by(n) %>%
  summarise(sig_results = n()/1000)

# Using the pwr package
library(pwr)

pwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = "one.sample")


significant_8 <- sum(results_8$pval < 0.05, na.rm = TRUE)

significant_40 <- sum(results_40$pval < 0.05, na.rm = TRUE) 
```

I utvalget n =8 så er det 227 p-verdier som er under p<0.05 og n =40 er det 865. Vi ser at det ved et større utvalg er flere studier som viser en statistisk signifikans

## Oppgave 7


```{r}
#| message: false
#| warning: false
#| code-fold: true

library(pwr)
effect_size <- 1.5 / 3 
alpha <- 0.05
n_8 <- 8 
power_8 <- pwr.t.test(d = effect_size, n = n_8, sig.level = 0.05, type = "one.sample", alternative = "two.sided")$power

n_40 <- 40
power_40 <- pwr.t.test(d = effect_size, n = n_40, sig.level = 0.05, type = "one.sample", alternative = "two.sided")$power
```

Det vi ser er at større utvalg n = 40 gir en større statistik styrke, enne et mindre utvalg n =8. 



## Oppgave 8

```{r}

#| message: false
#| warning: false
#| code-fold: true

library(tidyverse)

population <- rnorm(1000000, mean = 0, sd = 3)

results_8 <- data.frame(estimate = rep(NA, 1000), 
                         se = rep(NA, 1000), 
                         pval = rep(NA, 1000), 
                         n = 8)
results_40 <- data.frame(estimate = rep(NA, 1000), 
                          se = rep(NA, 1000), 
                          pval = rep(NA, 1000), 
                          n = 40)


for(i in 1:1000) {
  
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Modeller dataene
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Ekstraher verdier fra modellene
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
}


results_null <- bind_rows(results_8, results_40)


results_null %>%
  ggplot(aes(pval)) + 
  geom_histogram() +
  facet_wrap(~ n)


results_null %>%
  filter(pval < 0.05) %>%
  group_by(n) %>%
  summarise(sig_results = n()/1000)


false_positive_rate <- results_null %>%
  filter(pval < 0.05) %>%
  summarise(false_positives = n()) %>%
  pull(false_positives) / 2000  

false_positive_rate


```

Det er 0,053 av studiene som ville gitt falske positive svar. 

