---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Assignment 3: Drawing inference from statistical models, and statistical power {#assignment3}

This assignment is set up as a statistical laboratory, we will perform simulations and your assignment is to interpret and explain the results. Create a report based on the code used in the lab and make sure you answer the specified questions (1-8). You can be as creative as you want and explore the results further. 


```{r}
#| echo: false
#| label: "Standardscript for pakker"
#| warning: false
#| message: false


library(readxl)
library(tidyr)
library(exscidata)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(magrittr)
library(gt)
library(ggtext)
library(pwr)


```





```{r}
#| echo: false




set.seed(1)
population <- rnorm(1000000, mean = 1.5, sd = 3)

samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

m1 <- lm(y ~ 1, data = samp1)
m2 <- lm(y ~ 1, data = samp2)

# Skjul summary-output
invisible(summary(m1))
invisible(summary(m2))





```



## Spørsmål:

Et estimat representerer gjennomsnittet av det vi har målt i utvalget. Det vil i lm1 og lm2 estimat gjennomsnitt på den ene variablen (y) i de to ulike utvalgene. 

SE (standard error) er standardfeilen vil være et mål på hvordan et statistisk estimat til et utvalg kan variere fra populasjonen. For modellen m1 er standard error 1.25 dette viser at det er noe usikkerhet knyttet til et estimat av gjennomsnittet.

T-verdi kan ses på som en statistisk verdi hvor et forhold mellom estimatet og standardfeilen. 

**P-verdien** uttrykker sannsynligheten for å observere en teststatistikk som er like ekstrem eller mer ekstrem enn det faktiske resultatet, forutsatt at nullhypotesen (H₀) er sann. Den måler hvor godt dataene samsvarer med nullhypotesen og bidrar til å vurdere usikkerheten i resultatene. Lave p-verdier indikerer at resultatene sannsynligvis ikke skyldes tilfeldigheter, og gir dermed støtte for å forkaste H₀. Høye p-verdier tyder derimot på at resultatene kan forklares med tilfeldigheter, og gir ikke tilstrekkelig grunnlag for å forkaste H₀. Dermed fungerer p-verdien som et verktøy for å evaluere evidensen mot nullhypotesen og trekke konklusjoner basert på statistiske analyser. 

De to ulike modellene får ulike resultater en av grunnene til dette er at det er ulikt utvalg i de to ulike modellene i lm1 er det n =8, mens i lm2 er det n =40. Utvalgsstørrelsen vil ha en innvirkning på resultatene, ved at man har et større utvalg vil den statistiske styrken være høyere og det vil dermed være lettere å kunne oppdage om det vil være en reell effekt en ser. Det samme vil gjelde for standardfeil ved et større utvalg vil standardfeil til gjennomsnittet reduseres, en vil da ha mindre konfidensintervall og estimatene vil kunne bli mer presist.

De mørke skyggeområdene til modellen viser de mer "ekstreme" tilfellene og jo lengre ut på de mørke områdene man kommer, vil de resultatene være mindre sannsynlig å se.






```{r}
#| code-fold: true
#| message: false
#| warning: false

# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results <- bind_rows(results_8, results_40)

# Calculate standard deviation of the estimate and the average of the standard error (se)
results_summary <- results |> 
  group_by(n) |> 
  summarise(
    sd_estimate = sd(estimate),
    avg_se = mean(se)
  )


sd_est_8 <- sd(results$estimate[results$n == 8])
avg_se_8 <- mean(results$se[results$n == 8])

sd_est_40 <- sd(results$estimate[results$n == 40])
avg_se_40 <- mean(results$se[results$n == 40])

rounded_sd_est_8 <- round(sd_est_8, 2)
rounded_avg_se_8 <- round(avg_se_8, 2)
rounded_sd_est_40 <- round(sd_est_40, 2)
rounded_avg_se_40 <- round(avg_se_40, 2)


```

### Standard deviation of **estimate** and avg. **se** for each study. 


Grunnen til at tallene er såpass like som de er for **SD** og **avg se** er at begge beregningene er mål på variasjon. I denne sammenhengen er standardfeilen et mål på hvor mye utvalgsgjennomsnittet forventes å avvike fra det sanne populasjonsgjennomsnittet.

### P-value histogram

```{r}
#| code-fold: true
#| label: "P-verdi histogram SS8"

ggplot(results[results$n == 8, ], aes(x = pval)) +
  geom_histogram(binwidth = 0.05, fill = "blue", alpha = 0.6) +
  labs(title = "P-verdier fordeling til samplesize 8",
       x = "P-verdier",
       y = "frekvens") +
  theme_minimal()


```

Histrogrammet for en utvalgstørrelse på 8, ser vi at det er et flertall av obervasjoner med høye p-verdier. Dette henger sammen med lave statistiske poweren og liten utvalgstørrelse




```{r}
#| code-fold: true
#| label: "P-verdi histogram SS40"

ggplot(results[results$n == 40, ], aes(x = pval)) +
  geom_histogram(binwidth = 0.05, fill = "lightblue", alpha = 0.6) +
  labs(title = "P-verdier fordeling til samplesize 40",
       x = "P-verdier",
       y = "frekvens") +
  theme_classic()




```

For et histogram med utvalgstørrelsen på 40 ses det at flere av obervasjoene er sentrert mot lavere p-verdier. Dette fordi vi det er en større utvalgstørrelse som gir en større statistik power

### Antall studier med statistisk signifikans


```{r}
#| code-fold: true
#| label: "Calculate number of studies with stat signif"

alpha <- 0.05

significant_8 <- sum(results$pval[results$n == 8] < alpha)
significant_40 <- sum(results$pval[results$n == 40] < alpha)




```

 Med utvalgsstørrelse på 8 ser vi at det er `r significant_8` studier som viser statistisk signifikans, mens det ved  utvalgsstørrelse på 40 er  `r significant_40` studier som viser statistisk signifikans. Basert på dette som vi ser, ser vi at det ved et støøre utvalg vil være flere signifikante resultat. I denne situasjonen har jeg valgt å sette terskelen for signifikans til <0.05



### Power of a one-sample t-test

```{r}
#| code-fold: true
#| label: "Utregning av stat power"

effect_size <- 1.5 / 3

power_8 <- pwr.t.test(n = 8,
                      d = effect_size,
                      sig.level = alpha,
                      type = "one.sample")$power
rounded_power_8 <- round(power_8, 3)


power_40 <- pwr.t.test(n = 40,
                       d = effect_size,
                       sig.level = alpha,
                       type = "one.sample")$power

rounded_power_40 <- round(power_40, 3)

rounded_power_40_perc <- rounded_power_40 * 100




```


Når vi gjør beregninger av utlvalgstørrelsene ser vi at utvlagstørrelsen på 8 får en lavere statisitisk styrke (`r rounded_power_8`) enn det vi får på en utvalgstørrelse hvor vi har 40 (`r rounded_power_40`). Et større utvalg gjør vil det være høyere sannsynlighet for å kunne se den reelle effekten og at det ikke bare er en tilfeldighet. 


### Med signifikansnivå på 0.05 hvor mange studier gir "falsk positiv" ved gjennomføring av mange repeterte studier?

```{r}
#| code-fold: true
#| label: "Siste oppgave"


set.seed(1)
population <- rnorm(1000000, mean = 0, sd = 3)


# Create data frames to store the model estimates
results_8 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 8)  

results_40 <- data.frame(estimate = rep(NA, 1000), 
                      se = rep(NA, 1000), 
                      pval = rep(NA, 1000), 
                      n = 40)

# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample
# from the population. 

for(i in 1:1000) {
  
  # Draw a sample 
  samp1 <- data.frame(y = sample(population, 8, replace = FALSE))
  samp2 <- data.frame(y = sample(population, 40, replace = FALSE))

  # Model the data
  m1 <- lm(y ~ 1, data = samp1)
  m2 <- lm(y ~ 1, data = samp2)
  
  # Extract values from the models
  results_8[i, 1] <- coef(summary(m1))[1, 1]
  results_8[i, 2] <- coef(summary(m1))[1, 2]
  results_8[i, 3] <- coef(summary(m1))[1, 4]

  results_40[i, 1] <- coef(summary(m2))[1, 1]
  results_40[i, 2] <- coef(summary(m2))[1, 2]
  results_40[i, 3] <- coef(summary(m2))[1, 4]
  
  
}


# Save the results in a combined data frame

results_null <- bind_rows(results_8, results_40)


```


```{r}
#| code-fold: true
#| label: "Falske positive"


false_positive_8 <- sum(results_8$pval < 0.05)
false_positive_40 <- sum(results_40$pval < 0.05)


false_positive_8_alpha0.025 <- sum(results_8$pval < 0.025)
false_positive_40_alpha0.025 <- sum(results_40$pval < 0.025)

```

Når det gjøres 1000 repeterte studier, vil det være 50 falske positive om signifikansnivået er satt til 0.05. For utvalgstørrelsen på 8 fikk jeg da 49 og for utvalgstørrelsen på 40 fikk en 59 falske positive Hvis man velger å endre signifikansnivået til 0.025 vil en utlvalgstørrelse på 8 gi endel færre falske positive med 30 mens for utvlagstørrelsen på 40 vil det være 22.