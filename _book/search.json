[
  {
    "objectID": "02-regression-models.html",
    "href": "02-regression-models.html",
    "title": "2  Assignment 2: Regression models, predicting from data",
    "section": "",
    "text": "2.1 Introduksjon\nEn regresjonsmodell er en modell som kvantifiserer forholdet mellom en eller flere uavhengige variabler og en avhengig variabel. Innen medisin er regresjon den analysemtoden som er hyppigst anvendt. Det finnes forskjellige regresjonsmodeller. De vanligste er lineær regresjon, polynominal regresjon og logistisk regresjon. Hva man har av datasett vil bestemme hvilken regresjonsmodell som egner seg best å benytte (Pisica2022?).\nEn lineær regresjonsmodell er en modell der en kan estimere verdien av en avhengig variabel basert på verdien av andre kjente uavhengige variabler (Pisica2022?). I en slik modell benyttes en rett linje for å lage en modell som beskriver dataen. Følgende funksjon benyttes for å skape det lineære plottet:\nyi = b0 + b1xi + ei\nder yi er den avhengige variabelen som kan estimeres ved å benytte de uavhengige variablene b1xi og b0. b0 er skjæringspunktet til grafen og b1 er stigningstallet til grafen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Assignment 2: Regression models, predicting from data</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html",
    "href": "01-reliability-tools.html",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "",
    "text": "2 Introduksjon\nDet ble gjennomført fire testdager 28.08.2024, 29.08.2024, 9.09.2024 og 11.09.2024 for å teste VO2maks. Formålet med disse testene var å øve på å kunne gjennomføre fysiologiske tester med høy reliabilitet. Reliabilitet refererer til graden av konsistens eller pålitelighet i målinger evnen til å kunne reprodusere (Hopkins,2001), et eksempel på dette er ved fysiologisk testing som repeteres i forskningsprosjekter, der bedre reliabilitet vil indikere hvor god presisjonen er og måling av endring over tid (Hopkins,2001). Det er mange begreper som er relevante for å kunne si noe om reliabilitet, men standardavviket er et av disse. Standardavviket sier noe om hvor langt unna verdiens gjennomsnittlige avstand er fra gjennomsnittet (Spiegelhalter 2020)\nKroppens maksimale oksygenopptak (VO2maks ) sier noe om kroppens maksimale evne til å ta opp og omsette oksygen (Bassett and Howley 2000) . VO2maks kan beskrives ved hjelp av Ficks likning: VO2maks=MVmaks x a-vO2differansemaks. VO2maks måles ved at man måler hvor mye oksygen kroppen klarer å omsette pr minutt (Bassett and Howley 2000). Det finnes ulike måter og fremstille VO2maks på de to av disse er absolutt VO2maks beskrevet som (ml/min) eller relative tall relatert til kroppsvekt (ml/kg/min).\nVi har i resultat delen valgt å fremstille effekt maks (Wmaks) som er et mål på snitteffekt det siste minuttet av VO2maks testen basert på kroppsvekt. Wmaks/kg sett opp i sammenheng med den relative VO2maks (ml/kg/min). Forskning viser at at høy VO₂maks sammen med god mekanisk effektivitet og høy laktatterskel gir bedre utholdenhetsprestasjoner, noe som reflekteres i høyere Wmaks/kg (Joyner and Coyle 2008).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html#gjennomsnitt-og-standardavvik",
    "href": "01-reliability-tools.html#gjennomsnitt-og-standardavvik",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "4.1 Gjennomsnitt og standardavvik",
    "text": "4.1 Gjennomsnitt og standardavvik\n\n\n\n\n\n\nTabell fra alle grupper med gjennomsnitt og standardavvik i ()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n\nBorg(maks)\n19.2 (0.96)\n19 (0.82)\n18 (1.2)\n19 (0)\n19.5 (0.71)\n19 (0)\n17.5 (1.7)\n17 (NA)\n19.7 (0.58)\n20 (0)\n17.5 (0.71)\n18 (1.7)\n18.3 (0.58)\n18.8 (0.5)\n17 (1)\n19.5 (0.71)\n\n\nVO2maks\n(ml/kg/min)\n33.5 (1.5)\n43.7 (2.6)\n51.6 (4.1)\n37.1 (1.1)\n58.9 (0.64)\n45.5 (0.2)\n61.8 (1.9)\n43.5 (NA)\n58.8 (0.59)\n43.2 (0.89)\n56.5 (0.94)\n61.7 (3.1)\n51.3 (0.88)\n65.7 (1.1)\n39.8 (2.6)\n60.2 (1.2)\n\n\nWattmaks/kg\n2.5 (0.14)\n3.58 (0.044)\n3.6 (0.46)\n3 (0.2)\n5.18 (0.082)\n3.51 (0.1)\n5.24 (0.2)\n3.93 (NA)\n4.92 (0.038)\n3.76 (0.014)\n4.93 (0.049)\n5.6 (0.4)\n3.87 (0.062)\n5.51 (0.1)\n2.85 (0.12)\n4.63 (0.065)\n\n\nVO2maks\n(ml/min)\n3240 (150)\n2700 (160)\n4130 (300)\n2860 (52)\n4390 (48)\n3710 (6.4)\n5130 (140)\n2540 (NA)\n4650 (41)\n3100 (64)\n3640 (97)\n4480 (230)\n4590 (48)\n4520 (59)\n4100 (270)\n4960 (130)\n\n\nWattmaks\n243 (13)\n221 (2.8)\n288 (36)\n231 (13)\n387 (6.1)\n286 (7.5)\n435 (19)\n230 (NA)\n389 (2.1)\n269 (1.2)\n318 (0)\n407 (29)\n347 (6.9)\n380 (5.7)\n293 (12)\n382 (3.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nReliability relativ vo2maks T1&T2\n\n\nMEAN\nSD\nTE\nCV\n\n\n\n\n52.44\n1.83\n1.30\n2.47",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html#reliabilitet",
    "href": "01-reliability-tools.html#reliabilitet",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "4.2 Reliabilitet",
    "text": "4.2 Reliabilitet\nReliabiliteten mellom t1 og t2 er 2.47.\n\n\n\n\n\n\nReliability relativ vo2maks T3&T4\n\n\nMEAN\nSD\nTE\nCV\n\n\n\n\n48.64\n3.29\n2.32\n4.78\n\n\n\n\n\n\n\nReliabiliteten mellom t3 og t4 er 4.78.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html#korrelasjon-mellom-vo2maks-og-wattmaks-per-kg",
    "href": "01-reliability-tools.html#korrelasjon-mellom-vo2maks-og-wattmaks-per-kg",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "4.3 Korrelasjon mellom Vo2maks og Wattmaks per kg",
    "text": "4.3 Korrelasjon mellom Vo2maks og Wattmaks per kg\n\n\n\n\n\nFigur 1: Hvert punkt = én observasjon\n\n\n\n\nJeg fikk dessverre ikke til å gjøre om på hver enkelt farge, for å lettere kunne skille ulike id´er fra hverandre.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html#referanser",
    "href": "01-reliability-tools.html#referanser",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "4.4 Referanser",
    "text": "4.4 Referanser\n\n\n\n\nBassett, D R, Jr, and E T Howley. 2000. “Limiting Factors for Maximum Oxygen Uptake and Determinants of Endurance Performance.” Med. Sci. Sports Exerc. 32 (1): 70–84.\n\n\nHalperin, Israel, David B Pyne, and David T Martin. 2015. “Threats to Internal Validity in Exercise Science: A Review of Overlooked Confounding Variables.” Int. J. Sports Physiol. Perform. 10 (7): 823–29.\n\n\nJoyner, Michael J, and Edward F Coyle. 2008. “Endurance Exercise Performance: The Physiology of Champions.” J. Physiol. 586 (1): 35–44.\n\n\nSpiegelhalter, David. 2020. “Introducing the Art of Statistics: How to Learn from Data.” Numeracy 13 (1).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "03-statistical-inference.html",
    "href": "03-statistical-inference.html",
    "title": "3  Oppgave 1",
    "section": "",
    "text": "3.0.1 Oppgave 2\nDe to ulike modellene får ulike resultater en av grunnene til dette er at det er ulikt utvalg i de to ulike modellene i lm1 er det n =8, mens i lm2 er det n =40. Utvalgsstørrelsen vil ha en innvirkning på resultatene, ved at man har et større utvalg vil den statistiske styrken være høyere og det vil dermed være lettere å kunne oppdage om det vil være en reell effekt en ser. Det samme vil gjelde for standardfeil ved et større utvalg vil standardfeil til gjennomsnittet reduseres, en vil da ha mindre konfidensintervall og estimatene vil kunne bli mer presist.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Oppgave 1</span>"
    ]
  },
  {
    "objectID": "04-study-design.html",
    "href": "04-study-design.html",
    "title": "4  Assignment 4: Study designs",
    "section": "",
    "text": "4.1 Overview\nChoose an area of interest (e.g. protein supplementation for muscle hypertrophy or the effect of block periodization on VO2max). Find at least five original research studies1 in your selected area and describe strength and weakness of these studies. The report should focus on the design of the studies and selection of statistical tests to answer study aims. Conclude your report with a recommendation, how should future studies in your area be designed to best answer similar questions?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 4: Study designs</span>"
    ]
  },
  {
    "objectID": "04-study-design.html#footnotes",
    "href": "04-study-design.html#footnotes",
    "title": "4  Assignment 4: Study designs",
    "section": "",
    "text": "Avoid using review articles or meta-analyses↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Assignment 4: Study designs</span>"
    ]
  },
  {
    "objectID": "05-repeated-measurements.html",
    "href": "05-repeated-measurements.html",
    "title": "5  Assignment 5: Analyzing repeated measures experiments",
    "section": "",
    "text": "5.1 Assignment overview\nIn this assignment you will analyse and report on trial investigating the effect of resistance training volume on lean mass and muscle strength. The data are part of the exscidata package and can be accessed as data(\"strengthvolume\") and data(\"dxadata\"). Read the instructions carefully!",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 5: Analyzing repeated measures experiments</span>"
    ]
  },
  {
    "objectID": "05-repeated-measurements.html#assignment-overview",
    "href": "05-repeated-measurements.html#assignment-overview",
    "title": "5  Assignment 5: Analyzing repeated measures experiments",
    "section": "",
    "text": "Below you will find a basic outline of the report and example code that we worked on in class.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 5: Analyzing repeated measures experiments</span>"
    ]
  },
  {
    "objectID": "05-repeated-measurements.html#introduction",
    "href": "05-repeated-measurements.html#introduction",
    "title": "5  Assignment 5: Analyzing repeated measures experiments",
    "section": "5.2 Introduction",
    "text": "5.2 Introduction",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 5: Analyzing repeated measures experiments</span>"
    ]
  },
  {
    "objectID": "05-repeated-measurements.html#methods",
    "href": "05-repeated-measurements.html#methods",
    "title": "5  Assignment 5: Analyzing repeated measures experiments",
    "section": "5.3 Methods",
    "text": "5.3 Methods\n\n5.3.1 Participants and study overview\n\n\n5.3.2 Muscle strength and hypertrophy\n\n\n5.3.3 Data analysis and statistics",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 5: Analyzing repeated measures experiments</span>"
    ]
  },
  {
    "objectID": "05-repeated-measurements.html#results",
    "href": "05-repeated-measurements.html#results",
    "title": "5  Assignment 5: Analyzing repeated measures experiments",
    "section": "5.4 Results",
    "text": "5.4 Results\nThe average difference in lean mass changes between sets were 122.8, 95% CI: [8.6, 237], p = 0.036.\n\n## Time points in strength data set\n\nstrengthvolume %&gt;%\n  distinct(exercise)\n\n# A tibble: 6 × 1\n  exercise\n  &lt;chr&gt;   \n1 legpress\n2 legext  \n3 isok.60 \n4 isok.120\n5 isok.240\n6 isom    \n\n## Exploratory plot of strength data \n\nstr &lt;- strengthvolume %&gt;%\n  filter(include == \"incl\") %&gt;%\n  mutate(time = factor(time, levels = c(\"pre\", \"session1\", \n                                        \"week2\", \"week5\", \n                                        \"week9\", \"post\"))) %&gt;%\n  print()\n\n# A tibble: 2,856 × 8\n   participant sex   include time     sets     leg   exercise  load\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;   &lt;fct&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1 FP13        male  incl    pre      single   R     legpress   115\n 2 FP13        male  incl    pre      multiple L     legpress   115\n 3 FP13        male  incl    pre      single   R     legext      55\n 4 FP13        male  incl    pre      multiple L     legext      55\n 5 FP13        male  incl    session1 single   R     legpress   125\n 6 FP13        male  incl    session1 multiple L     legpress   125\n 7 FP13        male  incl    session1 single   R     legext      55\n 8 FP13        male  incl    session1 multiple L     legext      55\n 9 FP13        male  incl    week2    single   R     legpress   185\n10 FP13        male  incl    week2    multiple L     legpress   175\n# ℹ 2,846 more rows\n\nstr %&gt;%\n  ggplot(aes(time, \n             load, \n             group = paste(participant, sets), \n             color = sets)) + \n  geom_line() + \n  facet_wrap(~ exercise, scales = \"free\")\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n## How many measurements per participant\n\nstr %&gt;%\n  filter(!is.na(load)) %&gt;%\n  group_by(participant, exercise, sets) %&gt;%\n  summarise(n = n() ) %&gt;%\n  ggplot(aes(n, participant, color = sets)) +\n  geom_point() + \n  facet_wrap(~ exercise) + \n  theme(axis.text.y = element_blank())\n\n`summarise()` has grouped output by 'participant', 'exercise'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\n\n## Use pre and post data \n# Combine pre data prior to data analysis\n# per exercise, leg, participant, and sets\n\nstr %&gt;%\n  mutate(time = if_else(time %in% c(\"pre\", \"session1\"), \"pre\", time)) %&gt;%\n  \n  filter(time %in% c(\"pre\", \"post\")) %&gt;%\n  \n  summarise(load = max(load, na.rm = TRUE), \n            .by = c(participant, \n                    sex, \n                    time, \n                    sets,\n                    exercise,\n                    leg)) %&gt;%\n  \n  print()\n\nWarning: There were 7 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `load = max(load, na.rm = TRUE)`.\nℹ In group 62: `participant = \"FP6\"`, `sex = \"female\"`, `time = \"post\"`, `sets\n  = \"multiple\"`, `exercise = \"legpress\"`, `leg = \"L\"`.\nCaused by warning in `max()`:\n! no non-missing arguments to max; returning -Inf\nℹ Run `dplyr::last_dplyr_warnings()` to see the 6 remaining warnings.\n\n\n# A tibble: 816 × 7\n   participant sex    time  sets     exercise leg    load\n   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n 1 FP13        male   pre   single   legpress R     125  \n 2 FP13        male   pre   multiple legpress L     125  \n 3 FP13        male   pre   single   legext   R      55  \n 4 FP13        male   pre   multiple legext   L      55  \n 5 FP13        male   post  single   legpress R     230  \n 6 FP13        male   post  multiple legpress L     235  \n 7 FP13        male   post  single   legext   R      97.5\n 8 FP13        male   post  multiple legext   L     100  \n 9 FP16        female pre   single   legpress R      95  \n10 FP16        female pre   multiple legpress L      85  \n# ℹ 806 more rows",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 5: Analyzing repeated measures experiments</span>"
    ]
  },
  {
    "objectID": "05-repeated-measurements.html#discussion",
    "href": "05-repeated-measurements.html#discussion",
    "title": "5  Assignment 5: Analyzing repeated measures experiments",
    "section": "5.5 Discussion",
    "text": "5.5 Discussion",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 5: Analyzing repeated measures experiments</span>"
    ]
  },
  {
    "objectID": "05-repeated-measurements.html#conclusion",
    "href": "05-repeated-measurements.html#conclusion",
    "title": "5  Assignment 5: Analyzing repeated measures experiments",
    "section": "5.6 Conclusion",
    "text": "5.6 Conclusion",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Assignment 5: Analyzing repeated measures experiments</span>"
    ]
  },
  {
    "objectID": "06-vitenskapsteori.html",
    "href": "06-vitenskapsteori.html",
    "title": "6  Philosophy of science",
    "section": "",
    "text": "Vitenskapsfilosofi oppgave Ifølge Hume er det umulig å rasjonelt begrunne bruken av induksjon. Hva er argumentet for denne konklusjonen? Gi en innvending mot ett av premissene i Humes argument og prøv å svare på denne innvendingen på Humes vegne. Hume var en kjent filosof og stilte seg kritisk til bruken av induksjon. Hume mente at det umulig var rasjonelt å kunne begrunne bruken av induksjon (Alnes, 2024). Hume sine argumenter for dette var at hvert induktive argument forutsetter uniformitetsprinsippet. Uniformitetsprinsippet er antagelsen om at naturen oppfører seg konsekvent, slik at hendelser som har skjedd tidligere, også vil skje i fremtiden. Det andre argumentet er at uniformitetsprinsippet ikke har en rasjonell begrunnelse (Vassend, 2024, Dag1, PPT).\nHume hadde mange argumenter imot bruken av induksjon. Hume mente at induksjon blant annet baserte seg på empirisme, at det en erfarte i går vil kunne predikere at det samme skal skje i morgen. Et eksempel på dette er at siden sola sto opp i går, vil den også stå opp i morgen. Det Hume sitt syn stiller seg mest kritisk til er hvordan mangelen på en rasjonell begrunnelse er med på å anta fremtiden i eksemplet som er gitt over. Basert på den induktive tankegangen vil man lage sirkulære argument basert på premisset altså erfaringen man har i dag om at sola sto opp. Danner et nytt premiss om at sola står opp i morgen og i fremtiden, og at vi lager en konklusjon på at det vil skje. Med andre ord, for å rettferdiggjøre vår antagelse om at solen vil stige opp i morgen, må vi allerede tro på gyldigheten av induksjon, som i sin tur baserer seg på tidligere erfaringer. Hume sitt poeng er at vi baserer fremtidige hendelser på fortiden sine hendelser. En innvendig mot Humes sine premiss er det å kunne predikere fremtiden basert på fortiden. Mennesker har i tusener av år observert at solen står opp hver dag. Dette danner en empirisme for at det vil skje i morgen. Som menneske vil det være vanskelig å skulle drive forskning og leve et hverdagsliv om man ikke vil predikere fremtiden basert på empiristiske erfaringer. Humes svar på innvendingen om solens oppgang vil ta for seg ulike argumenter som belyser begrensningene ved induksjon. For det første vil han understreke at selv om vi har erfaring med at solen har steget opp hver dag, gir ikke dette en rasjonell garanti for at den vil fortsette å gjøre det. Våres erfaringer kan være intuitive, men Hume vil kunne argumentere for at det er ikke nødvendigvis er en logisk nødvendighet som binder fremtidens hendelser til hva fortiden viste, og det kan være en dag solen faktisk ikke står opp. Hume vil videre kunne påpeke muligheten for feilaktige observasjoner. Historisk har mennesket gjort mange feil og feil antakelser om naturen, for eksempel trodde en at jorden var flat og at den ble regnet som sentrum i solsystemet. Dette er eksempler på at menneskets observasjoner kan være begrensede eller feiltolkede, noe som gjør det risikabelt å basere forventninger om fremtiden utelukkende på tidligere erfaringer. Hume ville også peke på sirkulariteten i argumentasjonen. Når vi bruker tidligere observasjoner av solen for å rettferdiggjøre fremtidige forventninger, befinner vi oss i et sirkulært resonnement. Vi vil da anta at fortiden er relevant for fremtiden, men dette er en induktiv antagelse som selv krever gyldighet. Samlet sett ville Hume fremheve at selv om erfaring kan gi en intuitiv følelse av sikkerhet, er det essensielt å se begrensningene ved induksjon. Erfaring alene kan ikke garantere nødvendighet, observasjoner kan være feilaktige, og sirkulariteten i argumentasjonen underminerer påstanden om at vi kan forutsi fremtidige hendelser basert på fortiden. Dette skaper en dyp usikkerhet i vår forståelse av kunnskap og hvordan vi anvender induksjon i vitenskapelig tenkning.\nGi en kort beskrivelse av falsifikasjonisme og si litt om hvorfor Popper var motivert til å utvikle denne teorien. Presenter så ett problem med teorien og vurder hvorvidt problemet kan løses. Falsifikasjonisme er synet, assosiert med Popper, at vitenskapene ikke bør, eller kan, forsøke å bekrefte hypoteser. Hypotesene kan bare falsifiseres. For å falsifisere en hypotese trenger man ikke annet enn deduktive gyldige slutninger ihht Popper. Falsifiserbarhet, som demarkasjonskriterium for vitenskapelighet, altså kriteriet som skiller vitenskap fra ikke-vitenskapelige påstander. At en påstand er falsifiserbar innebærer at det er mulig å vise at den er usann, dersom den faktisk er usann. Popper var opptatt av hvordan falsifiserbarhet lar oss skille vitenskap fra pseudovitenskap. Hvis en påstand er falsifiserbar kan den følgelig karakteriseres som vitenskap. Det har med bakgrunn i at falsifisering av en hypotese følger deduktiv gyldig slutning. Bekreftelse innebærer brukt av induksjon som da ikke gir en sikker slutning. Asymmetri mellom bekreftelse og avkreftelse (Antonsen et.al, 2023). Vitenskapen gjør ikke fremskritt gjennom å bekrefte teorier, men gjennom en eliminasjonsprosess der hypoteser som ikke fungerer blir luket ut. Da får man en gradvis utvikling der teorier som motsetter seg falsifisering blir stående som dominerende. (inntil man eventuell får nye og mer overlevelsesdyktige konkurrenter som kommer på banen) Falsifisering av gale hypoteser gjør at vitenskapen har fremskritt og vokser. Herding av en hypotese eller teori betyr at den har blitt utsatt for mange tester og forsøk på falsifisering, men har overlevd disse uten å bli falsifisert. Dette styrker teoriens troverdighet og gir den en høy grad av vitenskapelig autoritet. Popper mente at ingen teori kan sies å være endelig bevist, men en “herdet” teori er den beste tilgjengelige vitenskapelige forklaringen på et fenomen.\nEt sentralt problem med Karl Poppers syn på vitenskapelig metode er at hans teori om falsifikasjon ikke tar høyde for kompleksiteten i hvordan hypoteser testes i praksis. Ifølge Quine-Duhem-teoremet er det umulig å teste en enkelt hypotese isolert; enhver vitenskapelig test involverer alltid flere hypoteser og antakelser (Antonsen et al., 2023). Dette skaper betydelige utfordringer når det kommer til å avgjøre hvilken hypotese som skal forkastes dersom testresultatene ikke stemmer overens med forventningene. Når et eksperiment ikke gir de forventede resultatene, kan forskere stå overfor en vanskelig beslutning. Siden flere hypoteser er involvert, kan de velge å forkaste observasjonene i stedet for den opprinnelige hypotesen (Popper, 1959). Dette kan føre til en situasjon der teorier holdes ved like, til tross for motstridende data, og dermed kan vitenskapen stagnere. I slike tilfeller blir reell kunnskap ikke fremmet, fordi det ikke tas de nødvendige skrittene for å kritisk vurdere eller forkaste hypoteser. For å håndtere problemene knyttet til Quine-Duhem-teoremet og Poppers falsifikasjonisme, kan en iverksette flere strategier. Hypotetisk-deduktiv metode, forskerne bør formulere hypoteser med klare og testbare prediksjoner. Ved å lage spesifikke, testbare forutsigelser kan det bli lettere å isolere hvilke hypoteser som er ansvarlige for et gitt resultat. Systematisk testing av tilleggs hypoteser såkalte adhoc hypoteser (Antonsen et.al, s.110-112, 2023) Forskerne kan utføre eksperimenter som eksplisitt tester tilleggs hypotesene. Ved å evaluere hvordan disse hypotesene påvirker resultatene, kan det bli lettere å identifisere hva som må forkastes dersom det oppstår avvik.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of science</span>"
    ]
  },
  {
    "objectID": "07-laboratory-report.html",
    "href": "07-laboratory-report.html",
    "title": "7  Molecular Laboratory report",
    "section": "",
    "text": "Select one laboratory assignment and write a detailed report.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Molecular Laboratory report</span>"
    ]
  },
  {
    "objectID": "03-statistical-inference.html#oppgave-3",
    "href": "03-statistical-inference.html#oppgave-3",
    "title": "3  Oppgave 1",
    "section": "3.1 Oppgave 3",
    "text": "3.1 Oppgave 3\nDe mørke skyggeområdene til modellen viser de mer “ekstreme” og at vi da kan forkaste null-hypotesen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Oppgave 1</span>"
    ]
  },
  {
    "objectID": "03-statistical-inference.html#oppgave-4",
    "href": "03-statistical-inference.html#oppgave-4",
    "title": "3  Oppgave 1",
    "section": "3.2 Oppgave 4",
    "text": "3.2 Oppgave 4\n\n\nCode\nlibrary(tidyverse)\n\n# Create data frames to store the model estimates\nresults_8 &lt;- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 8)  \n\nresults_40 &lt;- data.frame(estimate = rep(NA, 1000), \n                      se = rep(NA, 1000), \n                      pval = rep(NA, 1000), \n                      n = 40)\n\n# A for loop used to sample 1000 studies, each iteration (i) will draw a new sample\n# from the population. \n\nfor(i in 1:1000) {\n  \n  # Draw a sample \n  samp1 &lt;- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 &lt;- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Model the data\n  m1 &lt;- lm(y ~ 1, data = samp1)\n  m2 &lt;- lm(y ~ 1, data = samp2)\n  \n  # Extract values from the models\n  results_8[i, 1] &lt;- coef(summary(m1))[1, 1]\n  results_8[i, 2] &lt;- coef(summary(m1))[1, 2]\n  results_8[i, 3] &lt;- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] &lt;- coef(summary(m2))[1, 1]\n  results_40[i, 2] &lt;- coef(summary(m2))[1, 2]\n  results_40[i, 3] &lt;- coef(summary(m2))[1, 4]\n  \n  \n}\n\n\n# Save the results in a combined data frame\n\nresults &lt;- bind_rows(results_8, results_40)\n\n\n\n\nCode\nsd_est_8 &lt;- sd (results_8$estimate)\nmean_se_8 &lt;- mean(results_8$se)\n\nsd_est_40 &lt;- sd (results_40$estimate)\nmean_se_40 &lt;- mean(results_40$se)\n\n\nVi får ganske like tall i modellene for sd og mean er at beregningene er et mål på variasjonen, vi ser at i disse to utvalgene at det er forholdsvis likt er fordi det er en beregning på variasjon.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Oppgave 1</span>"
    ]
  },
  {
    "objectID": "03-statistical-inference.html#oppgave-5",
    "href": "03-statistical-inference.html#oppgave-5",
    "title": "3  Oppgave 1",
    "section": "3.3 Oppgave 5",
    "text": "3.3 Oppgave 5\n\n# Example code for copy and paste\n\n# A two facets histogram can be created with ggplot2\nresults %&gt;%\n  ggplot(aes(pval)) + \n  geom_histogram() +\n  facet_wrap(~ n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n# Count the proportion of tests below a certain p-value for each \nresults %&gt;%\n  filter(pval &lt; 0.05) %&gt;%\n  group_by(n) %&gt;%\n  summarise(sig_results = n()/1000)\n\n# A tibble: 2 × 2\n      n sig_results\n  &lt;dbl&gt;       &lt;dbl&gt;\n1     8       0.227\n2    40       0.865\n\n# Using the pwr package\nlibrary(pwr)\n\npwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 40\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8693981\n    alternative = two.sided\n\n\n\n## Oppgave 5\n\nI de to histogrammene har vi ulike størrelse på utvalget n =8 og n =40. Ved å se på histogrammene ser vi at i utvalget med n = 8 er det et mer spredt fordeling av p-verdiene og at få p-verdier ligger i signifikansområdet. Et mindre utvalg gir lavere statistisk styrke og at det vil være mindre sannsynligheten for å kunne oppdage om et forsøk faktisk gir en effekt, samt at det er større spredning i utvalget som ikke gir en signifikant p-verdi. Ser vi på histogrammet med et utvalg n =40 ligger p-verdiene mer samlet og større del av utvalget ligger i det signifikante området, dette gjør at den statiske styrken er høyere. Ved en høy statistisk styrke og flere signifikante p-verdier gjør at det vil være en høyere sannsynlighet for å kunne oppdage de faktiske effektene.\n\n## Oppgave 6\n\n::: {.cell}\n\n```{.r .cell-code}\n#| message: false\n#| warning: false\n#| code-fold: true\n\nlibrary(tidyverse)\nlibrary(pwr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Count the proportion of tests below a certain p-value for each \nresults %&gt;%\n  filter(pval &lt; 0.05) %&gt;%\n  group_by(n) %&gt;%\n  summarise(sig_results = n()/1000)\n\n# A tibble: 2 × 2\n      n sig_results\n  &lt;dbl&gt;       &lt;dbl&gt;\n1     8       0.227\n2    40       0.865\n\n# Using the pwr package\nlibrary(pwr)\n\npwr.t.test(n = 40, sig.level = 0.05, d = 1.5/3, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 40\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8693981\n    alternative = two.sided\n\nsignificant_8 &lt;- sum(results_8$pval &lt; 0.05, na.rm = TRUE)\n\nsignificant_40 &lt;- sum(results_40$pval &lt; 0.05, na.rm = TRUE) \n:::\nI utvalget n =8 så er det 227 p-verdier som er under p&lt;0.05 og n =40 er det 865. Vi ser at det ved et større utvalg er flere studier som viser en statistisk signifikans",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Oppgave 1</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html#part-1---lactate-thresholds",
    "href": "02-regression-models.html#part-1---lactate-thresholds",
    "title": "2  Assignment 2: Regression models, predicting from data",
    "section": "2.2 Part 1 - Lactate thresholds",
    "text": "2.2 Part 1 - Lactate thresholds\n\n2.2.1 Metode\nDataene ble sortert i mer passende format (tidydata) for å gjøre det lettere med modellene våre senere. Deretter ble det gjort ulike regresjonsmodeller for å fremstille dataene våre. Nye skjæringspunkter ble tegnet for å illustrere treningsintensitet ved ulike laktatverdier.\n\n\n2.2.2 Resultat\n\n\nCode\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(exscidata)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(gt)\nlibrary(ggtext)\n\n# Kalkuler treningsintensitet ved 2 og 4 mmol/L\n\nw &lt;- cyclingstudy |&gt; \n  select(subject, group, timepoint, lac.225:lac.375) |&gt; \n  filter(timepoint == \"pre\", subject == 10) |&gt; \n  pivot_longer(names_to = \"watt\", \n               values_to = \"lac\",\n               names_prefix = \"lac.\", \n               names_transform = list(watt = as.numeric),\n               cols = lac.225:lac.375)\n  \nmod &lt;- lm(lac ~ watt, data = w)\n\n\n\nw |&gt; \n  ggplot(aes(watt, lac, group = subject)) +\n  labs(x = \"Watt\",\n       y = \"Laktat\") +\n  geom_point(size = 3, shape = 21, fill = \"gold\") + \n  geom_line(lty = 2) +\n  geom_smooth(method = lm, se = FALSE) +\n  geom_smooth(method = lm, se = FALSE, formula = y ~ poly(x, 2), color = \"lightgreen\") +\n  geom_smooth(method = lm, se = FALSE, formula = y ~ poly(x, 3), color = \"lightpink\") +\n  coord_cartesian(xlim = c(220, 380)) +\n  geom_hline(yintercept = 2, color = \"red\") +\n  geom_hline(yintercept = 4, color = \"purple\") +\n  # Legger inn en vertikal linje, med y = 2mmol, skjæringspunkt 308W, tatt på øyemål.\n  geom_vline(xintercept = 309, linewidth = 1, alpha = 0.8) +\n  # Legger inn en vertikal linje med y = 4mmol, skjæringspunkt 342W, tatt på øyemål.\n  geom_vline(xintercept = 342, linewidth = 1, alpha = 0.8) +\n  theme_minimal()\n\n\n\n\n\nFigur 1: Gule punkter = laktat og watt, blå linje = lineær regresjon, grønn linje = andregradsligning, rosa = tredjegradsligning.\n\n\n\n\nCode\nx2lac &lt;- (2 - coef(mod)[1]) / coef(mod)[2]\nx4lac &lt;- (4 - coef(mod)[1]) / coef(mod)[2]\n\n\n\n\n2.2.3 Diskusjon\nVi har valgt å se på subject 10 fra datasettet Cyclingstudy. Vi gjør om datasettet til tidydata. Dette gjør vi for å gi watt og laktat hver sine verdier. Vi plotter inn laktatverdier og wattverdier (gule punkter). Deretter tegner vi en stiplet linje som følger punktene. Vi gjør en regresjonsanalyse, først en lineær modell (blå linje), deretter en andregradsligning (grønn) og til slutt en tredjegradsligning (rosa). Disse bruker vi for å observere hvilken modell som passer best i dette tilfellet.\nFor å understreke hvor unøyaktig den lineære modellen er i dette tilfellet, kan man på øyemål se at laktaten på 300W viser omtrent 2.4 mmol × L-1. Den faktiske laktaten på 300W er 1.69 mmol × L-1.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Assignment 2: Regression models, predicting from data</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html#part-2---predicting-sizes-of-dna-fragments",
    "href": "02-regression-models.html#part-2---predicting-sizes-of-dna-fragments",
    "title": "2  Assignment 2: Regression models, predicting from data",
    "section": "2.3 Part 2 - Predicting sizes of DNA fragments",
    "text": "2.3 Part 2 - Predicting sizes of DNA fragments\n\n2.3.1 Metode\nFor å kunne predikere kalibreringskurven til qPCR, er det en rekke prosesser på molekylærlabben som er gjort på forhånd før det kunne kjørers i R-studio.\nFor å kunne kjøre et PCR på en agrose gel 2%, ble det først tatt helbod fra en forsøksperson for å kunne ha et ekstrahert DNA. Helblodet vært igjen ulike prosesser hvor det er tilsatt ulike løsninger og tilsatt ulike primere. Vi står da igjen med et PCR-produkt. Det har videre blitt kjørt en elektroforese for å kunne separere DNA fragmentene fra PCR reaksjonen. Når elektroforesen var ferdig, ble det tatt et bilde av agrose gel 2%.\nVidere har bildet fra elektroforesen blitt analysert ved hjelp av ImageJFiji og videre dataanalyser gjort i R og R studio. PCR-reaksjoner blir bestemt av primerdesign og dens spesifisitet.\n\n\n2.3.2 Resultat\n\n\nCode\nladder &lt;- data.frame(dist = c(374.5, 396.5, 423.5, 458.5, 496.5, 547.5,607.5,688.5,734.5,792.5,860.5,936.5,1035.5), \n                     \n                     mw = c(1000, 900, 800, \n                            700, 600, 500,\n                            400, 300, 250, \n                            200, 150, 100, 50))\n            \n\n# Create a new data frame of unknowns\nunknown &lt;- data.frame(dist = c(1208.5, 600.5, 18.5, 383.5, 408.5, 436.5, 470.5, 508.5, 559.5, 618.5, 696.5, 742.5, 798.5, 862.5, 935.5, 993.5))\n\n# Fit the model\ncal &lt;- lm(log(mw) ~ dist, data = ladder)\n\n\n\npreds &lt;- exp(predict(cal, newdata = unknown))\n\n\n\nladder %&gt;% \n  ggplot(aes(dist, log(mw))) + \n           geom_point() +\n  geom_abline(intercept = coef(cal)[1], slope = coef(cal)[2])\n\n\n\n\n\n\n\n\n\nCode\ndataframe2 &lt;- data.frame(unknowns = c(1208.5, 600.5, 18.5, 383.5, 408.5, 436.5, 470.5, 508.5, 559.5, 618.5, 696.5, 742.5, 798.5, 862.5, 935.5, 993.5),\n                         (preds))\n  dataframe2 |&gt; gt()\n\n\n\n\n\n\n\n\nunknowns\nX.preds.\n\n\n\n\n1208.5\n31.22469\n\n\n600.5\n400.04598\n\n\n18.5\n4595.75349\n\n\n383.5\n994.08908\n\n\n408.5\n895.12164\n\n\n436.5\n795.92770\n\n\n470.5\n690.13619\n\n\n508.5\n588.44932\n\n\n559.5\n475.11729\n\n\n618.5\n370.95290\n\n\n696.5\n267.43845\n\n\n742.5\n220.50796\n\n\n798.5\n174.34415\n\n\n862.5\n133.29586\n\n\n935.5\n98.13646\n\n\n993.5\n76.94317\n\n\n\n\n\n\n\n\n\n2.3.3 Diskusjon",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Assignment 2: Regression models, predicting from data</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html#part-3---interpreting-a-regression-table",
    "href": "02-regression-models.html#part-3---interpreting-a-regression-table",
    "title": "2  Assignment 2: Regression models, predicting from data",
    "section": "2.4 Part 3 - Interpreting a regression table",
    "text": "2.4 Part 3 - Interpreting a regression table\n\n2.4.1 Metode\n\n\n2.4.2 Resultat\n\n\nCode\nlibrary(exscidata)\nlibrary(tidyverse)\n\n# sammenheng mellom tykkelse vastus lateralis t2 og konsentrasjon av testosterone ved t2\n\ndat &lt;- hypertrophy |&gt; \n  select(GROUP, TRAINING_AGE, AGE, CLUSTER, VL_T2, TESTOSTERONE_T1, TESTOSTERONE_T2)\n\nm &lt;- lm(TESTOSTERONE_T1 ~ TRAINING_AGE, dat)\n\n  dat |&gt; \n  ggplot(aes(TRAINING_AGE, TESTOSTERONE_T1)) +\n    labs(x = \"Treningsalder (år)\",\n         y = expression(Testosteronverdier ~ ng %.% dl^{-1})) +  \n    # use expression for superscript\n    \n  geom_point(size = 3, shape = 21, fill = \"orange\") +\n    \n  geom_abline(intercept = coef(m)[1], slope = coef(m)[2], color = \"steelblue\", size = 1) +\n    \n    geom_hline(yintercept = coef(m)[1] + coef(m)[2] * 10, color = \"darkgreen\") +\n    \n    geom_vline(xintercept = 10, color = \"darkred\") +\n    \n    scale_y_continuous(breaks = c(200, 354, 400, 600, 800, 1000), \n                       labels = c(200, \"testo10\", 400, 600, 800, 1000)) + \n    \n    theme_bw()\n\n\n\n\n\nFigur 3: Sammenheng mellom treningsalder og testosteronverdier i blodet\n\n\n\n\nCode\n  # Den lineære modellen forteller i dette tilfellet at for hvert år man trener, så vil nivå av testosterone synke med 20.51 ng*dl&lt;sup&gt;-1&lt;/sup&gt;. I tillegg kan man estimere testonivå etter å ha trent i 10 år. Dette vil vi gjøre med følgende utregning: \n  \ntesto10 &lt;- coef(m)[1] + coef(m)[2] * 10\ntesto10rounded &lt;- round(testo10, 2)\n  \n# testosteronnivå etter 10 år med trening estimeres til 354.26 ng*dl^-1\n\n\n\n\n2.4.3 Diskusjon\nFra datasettet hypertrophy valgte vi å se på sammenhengen mellom testosteronkonsentrasjon i blodet (ng × dl-1) og treningsalder (antall år med trening). Den lineære modellen forteller at testosteronkonsentrasjonen i blodet synker med 20.51 ng × dl-1 for hvert treningsår. Etter 10 år med trening, estimerer den lineære modellen et testosteronnivå på 354.26 ng × dl-1.\nAnalysen av dataene viser en p-verdi på 0,1779, noe som indikerer at det ikke er statistisk signifikant bevis for en sammenheng mellom treningsalder og nivået av testosteron i blodet. Siden p-verdien er høyere enn det vanlige signifikansnivået på 0,05, kan vi ikke avvise nullhypotesen, som antyder at det ikke er noen betydelig effekt eller sammenheng mellom de to variablene i dette datasettet. Dette betyr at variasjonen i testosteronnivåer ikke ser ut til å være relatert til hvor lenge individene har trent.\nI analysen av sammenhengen mellom treningsalder og testosteronnivåer i blodet ses det en t-verdi på 6.250. Den høye t-verdien på 6.250, og en p-verdi på 0,1779. Denne p-verdien er høyere enn det vanlige signifikansnivået på 0,05, noe som betyr at vi ikke har tilstrekkelig statistisk bevis for å avvise nullhypotesen. Selv om t-verdien indikerer en mulig sammenheng mellom treningsalder og testosteronnivå, er det ikke nok evidens til å konkludere med at denne sammenhengen er signifikant. Dermed kan vi konkludere med at selv om det kan være en tendens til en sammenheng mellom treningsalder og testosteronnivåer, er resultatene fra denne analysen ikke sterke nok til å si at treningsalder har en reell effekt på testosteronnivåene i blodet.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Assignment 2: Regression models, predicting from data</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html#referanser",
    "href": "02-regression-models.html#referanser",
    "title": "2  Assignment 2: Regression models, predicting from data",
    "section": "2.5 Referanser",
    "text": "2.5 Referanser",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Assignment 2: Regression models, predicting from data</span>"
    ]
  },
  {
    "objectID": "03-statistical-inference.html#oppgave-7",
    "href": "03-statistical-inference.html#oppgave-7",
    "title": "3  Oppgave 1",
    "section": "3.4 Oppgave 7",
    "text": "3.4 Oppgave 7\n\n\nCode\nlibrary(pwr)\neffect_size &lt;- 1.5 / 3 \nalpha &lt;- 0.05\nn_8 &lt;- 8 \npower_8 &lt;- pwr.t.test(d = effect_size, n = n_8, sig.level = 0.05, type = \"one.sample\", alternative = \"two.sided\")$power\n\nn_40 &lt;- 40\npower_40 &lt;- pwr.t.test(d = effect_size, n = n_40, sig.level = 0.05, type = \"one.sample\", alternative = \"two.sided\")$power\n\n\nDet vi ser er at større utvalg n = 40 gir en større statistik styrke, enne et mindre utvalg n =8.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Oppgave 1</span>"
    ]
  },
  {
    "objectID": "03-statistical-inference.html#oppgave-8",
    "href": "03-statistical-inference.html#oppgave-8",
    "title": "3  Oppgave 1",
    "section": "3.5 Oppgave 8",
    "text": "3.5 Oppgave 8\n\n#| message: false\n#| warning: false\n#| code-fold: true\n\nlibrary(tidyverse)\n\npopulation &lt;- rnorm(1000000, mean = 0, sd = 3)\n\nresults_8 &lt;- data.frame(estimate = rep(NA, 1000), \n                         se = rep(NA, 1000), \n                         pval = rep(NA, 1000), \n                         n = 8)\nresults_40 &lt;- data.frame(estimate = rep(NA, 1000), \n                          se = rep(NA, 1000), \n                          pval = rep(NA, 1000), \n                          n = 40)\n\n\nfor(i in 1:1000) {\n  \n  samp1 &lt;- data.frame(y = sample(population, 8, replace = FALSE))\n  samp2 &lt;- data.frame(y = sample(population, 40, replace = FALSE))\n\n  # Modeller dataene\n  m1 &lt;- lm(y ~ 1, data = samp1)\n  m2 &lt;- lm(y ~ 1, data = samp2)\n  \n  # Ekstraher verdier fra modellene\n  results_8[i, 1] &lt;- coef(summary(m1))[1, 1]\n  results_8[i, 2] &lt;- coef(summary(m1))[1, 2]\n  results_8[i, 3] &lt;- coef(summary(m1))[1, 4]\n\n  results_40[i, 1] &lt;- coef(summary(m2))[1, 1]\n  results_40[i, 2] &lt;- coef(summary(m2))[1, 2]\n  results_40[i, 3] &lt;- coef(summary(m2))[1, 4]\n}\n\n\nresults_null &lt;- bind_rows(results_8, results_40)\n\n\nresults_null %&gt;%\n  ggplot(aes(pval)) + \n  geom_histogram() +\n  facet_wrap(~ n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nresults_null %&gt;%\n  filter(pval &lt; 0.05) %&gt;%\n  group_by(n) %&gt;%\n  summarise(sig_results = n()/1000)\n\n# A tibble: 2 × 2\n      n sig_results\n  &lt;dbl&gt;       &lt;dbl&gt;\n1     8       0.044\n2    40       0.049\n\nfalse_positive_rate &lt;- results_null %&gt;%\n  filter(pval &lt; 0.05) %&gt;%\n  summarise(false_positives = n()) %&gt;%\n  pull(false_positives) / 2000  \n\nfalse_positive_rate\n\n[1] 0.0465\n\n\nDet er 0,053 av studiene som ville gitt falske positive svar.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Oppgave 1</span>"
    ]
  }
]